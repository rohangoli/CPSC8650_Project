{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6889786a-1ab6-45b8-b423-ece44857c28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import nibabel as nib\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from scipy import ndimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ceb1b6f-63bd-4cc9-8d11-e854854bf71e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Brain scans: 3\n"
     ]
    }
   ],
   "source": [
    "scan_paths = [\n",
    "    os.path.join(os.getcwd(), \"data/BET_BSE_DATA\", x)\n",
    "    for x in os.listdir(\"data/BET_BSE_DATA\")\n",
    "]\n",
    "\n",
    "print(\"Brain scans: \" + str(len(scan_paths)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "141ed6e4-6126-4692-aa99-eb297f90c341",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_nifti_file(filepath):\n",
    "    \"\"\"Read and load volume\"\"\"\n",
    "    # Read file\n",
    "    scan = nib.load(filepath)\n",
    "    # Get raw data\n",
    "    scan = scan.get_fdata()\n",
    "    return scan\n",
    "\n",
    "\n",
    "def normalize(volume):\n",
    "    \"\"\"Normalize the volume\"\"\"\n",
    "    min = -1000\n",
    "    max = 400\n",
    "    volume[volume < min] = min\n",
    "    volume[volume > max] = max\n",
    "    volume = (volume - min) / (max - min)\n",
    "    volume = volume.astype(\"float32\")\n",
    "    return volume\n",
    "\n",
    "\n",
    "def resize_volume(img):\n",
    "    \"\"\"Resize across z-axis\"\"\"\n",
    "    # Set the desired depth\n",
    "    desired_depth = 64\n",
    "    desired_width = 128\n",
    "    desired_height = 128\n",
    "    # Get current depth\n",
    "    current_depth = img.shape[-1]\n",
    "    current_width = img.shape[0]\n",
    "    current_height = img.shape[1]\n",
    "    # Compute depth factor\n",
    "    depth = current_depth / desired_depth\n",
    "    width = current_width / desired_width\n",
    "    height = current_height / desired_height\n",
    "    depth_factor = 1 / depth\n",
    "    width_factor = 1 / width\n",
    "    height_factor = 1 / height\n",
    "    # Rotate\n",
    "    img = ndimage.rotate(img, 90, reshape=False)\n",
    "    # Resize across z-axis\n",
    "    img = ndimage.zoom(img, (width_factor, height_factor, depth_factor), order=1)\n",
    "    return img\n",
    "\n",
    "\n",
    "def process_scan(path):\n",
    "    \"\"\"Read and resize volume\"\"\"\n",
    "    # Read scan\n",
    "    volume = read_nifti_file(path)\n",
    "    # Normalize\n",
    "    volume = normalize(volume)\n",
    "    # Resize width, height and depth\n",
    "    volume = resize_volume(volume)\n",
    "    return volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "480ebc67-6cc4-42e7-8638-7629f0d4ef70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total no. of rows: 1312\n",
      "Field names are:Filename, Recognizable-Facial-Feature, Brain-Feature-Loss\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    " \n",
    "# csv file name\n",
    "filename = \"data/BET_BSE_DATA/Label_file.csv\"\n",
    " \n",
    "# initializing the titles and rows list\n",
    "fields = []\n",
    "labels_facical_feature_dict = dict()\n",
    "labels_brain_feature_dict = dict()\n",
    " \n",
    "# reading csv file\n",
    "with open(filename, 'r') as csvfile:\n",
    "    # creating a csv reader object\n",
    "    csvreader = csv.reader(csvfile)\n",
    "     \n",
    "    # extracting field names through first row\n",
    "    fields = next(csvreader)\n",
    " \n",
    "    # extracting each data row one by one\n",
    "    for row in csvreader:\n",
    "        #print(row)\n",
    "        if row[1].lower() == 'yes':\n",
    "            labels_facical_feature_dict[row[0]+'.gz'] = 1\n",
    "        else:\n",
    "            labels_facical_feature_dict[row[0]+'.gz'] = 0\n",
    "        if row[2].lower() == 'yes':\n",
    "            labels_brain_feature_dict[row[0]+'.gz'] = 1\n",
    "        else:\n",
    "            labels_brain_feature_dict[row[0]+'.gz'] = 0\n",
    " \n",
    "    # get total number of rows\n",
    "    print(\"Total no. of rows: %d\"%(csvreader.line_num))\n",
    "\n",
    "#printing the field names\n",
    "print('Field names are:' + ', '.join(field for field in fields))\n",
    "#print(labels_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c2e4329f-2e50-47c8-9958-da925d6fab38",
   "metadata": {},
   "outputs": [],
   "source": [
    "brain_scans=[]\n",
    "labels_facial_feature=[]\n",
    "labels_brain_feature=[]\n",
    "labels_to_file=[]\n",
    "for path in os.listdir(\"data/BET_BSE_DATA/files\"):\n",
    "    #brain_scans.append(process_scan(\"/home/joelkik/DataMining/BET_BSE_DATA/files/\"+path))\n",
    "    labels_facial_feature.append(labels_facical_feature_dict[path])\n",
    "    labels_brain_feature.append(labels_brain_feature_dict[path])\n",
    "    labels_to_file.append(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e0b0035c-7196-4928-88cd-5e420fe6a074",
   "metadata": {},
   "outputs": [],
   "source": [
    "#brain_scans_np = np.array(brain_scans)\n",
    "labels_facial_feature_np = np.array(labels_facial_feature)\n",
    "labels_brain_feature_np = np.array(labels_brain_feature)\n",
    "brain_scans_np=np.load('brain_scans_np.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0227377d-5b0a-438a-aefb-4541eff38e4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"3dcnn\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 128, 128, 64, 1)  0         \n",
      "                             ]                                   \n",
      "                                                                 \n",
      " conv3d_4 (Conv3D)           (None, 126, 126, 62, 64)  1792      \n",
      "                                                                 \n",
      " max_pooling3d_4 (MaxPooling  (None, 63, 63, 31, 64)   0         \n",
      " 3D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 63, 63, 31, 64)   256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv3d_5 (Conv3D)           (None, 61, 61, 29, 64)    110656    \n",
      "                                                                 \n",
      " max_pooling3d_5 (MaxPooling  (None, 30, 30, 14, 64)   0         \n",
      " 3D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 30, 30, 14, 64)   256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv3d_6 (Conv3D)           (None, 28, 28, 12, 128)   221312    \n",
      "                                                                 \n",
      " max_pooling3d_6 (MaxPooling  (None, 14, 14, 6, 128)   0         \n",
      " 3D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_6 (Batc  (None, 14, 14, 6, 128)   512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv3d_7 (Conv3D)           (None, 12, 12, 4, 256)    884992    \n",
      "                                                                 \n",
      " max_pooling3d_7 (MaxPooling  (None, 6, 6, 2, 256)     0         \n",
      " 3D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_7 (Batc  (None, 6, 6, 2, 256)     1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " global_average_pooling3d_1   (None, 256)              0         \n",
      " (GlobalAveragePooling3D)                                        \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 512)               131584    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,352,897\n",
      "Trainable params: 1,351,873\n",
      "Non-trainable params: 1,024\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def get_model(width=128, height=128, depth=64):\n",
    "    \"\"\"Build a 3D convolutional neural network model.\"\"\"\n",
    "\n",
    "    inputs = keras.Input((width, height, depth, 1))\n",
    "\n",
    "    x = layers.Conv3D(filters=64, kernel_size=3, activation=\"relu\")(inputs)\n",
    "    x = layers.MaxPool3D(pool_size=2)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "\n",
    "    x = layers.Conv3D(filters=64, kernel_size=3, activation=\"relu\")(x)\n",
    "    x = layers.MaxPool3D(pool_size=2)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "\n",
    "    x = layers.Conv3D(filters=128, kernel_size=3, activation=\"relu\")(x)\n",
    "    x = layers.MaxPool3D(pool_size=2)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "\n",
    "    x = layers.Conv3D(filters=256, kernel_size=3, activation=\"relu\")(x)\n",
    "    x = layers.MaxPool3D(pool_size=2)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "\n",
    "    x = layers.GlobalAveragePooling3D()(x)\n",
    "    x = layers.Dense(units=512, activation=\"relu\")(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "\n",
    "    outputs = layers.Dense(units=1, activation=\"sigmoid\")(x)\n",
    "\n",
    "    # Define the model.\n",
    "    model = keras.Model(inputs, outputs, name=\"3dcnn\")\n",
    "    return model\n",
    "\n",
    "\n",
    "# Build model.\n",
    "model = get_model(width=128, height=128, depth=64)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ddadc472-2fda-4102-baf4-5ebb15109992",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = keras.models.load_model(\"3d_brain_image_classification.h5\")\n",
    "model.load_weights(\"3d_brain_image_classification.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7eb16379-3279-4e26-91f6-4464ea1af7aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1311"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels_facial_feature_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f148a2df-0883-4882-9474-c4bf69f18ac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scan File:  IXI369-Guys-0924-T1_bse_high_s75_r2.nii.gz , Actual:  0 , Predicted:  0\n",
      "Scan File:  IXI270-Guys-0847-T1_bet_88.nii.gz , Actual:  0 , Predicted:  0\n",
      "Scan File:  IXI333-IOP-0926-T1_bse_default.nii.gz , Actual:  1 , Predicted:  1\n",
      "Scan File:  IXI483-HH-2177-T1_bet_12.nii.gz , Actual:  1 , Predicted:  1\n",
      "Scan File:  IXI464-IOP-1029-T1_bet_08.nii.gz , Actual:  1 , Predicted:  1\n",
      "Scan File:  IXI205-HH-1649-T1_bet_73.nii.gz , Actual:  0 , Predicted:  0\n",
      "Scan File:  IXI544-HH-2395-T1_bse_less_s51_r1.nii.gz , Actual:  1 , Predicted:  1\n",
      "Scan File:  IXI033-HH-1259-T1_bet_76.nii.gz , Actual:  0 , Predicted:  0\n",
      "Scan File:  IXI260-HH-1805-T1_bet_12.nii.gz , Actual:  1 , Predicted:  1\n",
      "Scan File:  IXI241-Guys-0833-T1_bse_high_s74_r2.nii.gz , Actual:  0 , Predicted:  0\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    prediction = model.predict(np.expand_dims(brain_scans_np[i], axis=0))[0]\n",
    "    print(\"Scan File: \", labels_to_file[i], \", Actual: \", labels_facial_feature_np[i], \", Predicted: \",round(float(prediction)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "dcc2effc-c8f0-4274-ba74-a1685c0668e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds_ff = []\n",
    "for i in range(len(labels_facial_feature_np)):\n",
    "    prediction = model.predict(np.expand_dims(brain_scans_np[i], axis=0))[0]\n",
    "    y_preds_ff.append(round(float(prediction)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c6d03f95-3cc3-4c3c-99c4-e84896db6289",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"3d_brain_feature_loss_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "927ce761-4e77-4050-b6b3-e677bc712ba3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scan File:  IXI369-Guys-0924-T1_bse_high_s75_r2.nii.gz , Actual:  1 , Predicted:  1\n",
      "Scan File:  IXI270-Guys-0847-T1_bet_88.nii.gz , Actual:  1 , Predicted:  1\n",
      "Scan File:  IXI333-IOP-0926-T1_bse_default.nii.gz , Actual:  0 , Predicted:  0\n",
      "Scan File:  IXI483-HH-2177-T1_bet_12.nii.gz , Actual:  0 , Predicted:  0\n",
      "Scan File:  IXI464-IOP-1029-T1_bet_08.nii.gz , Actual:  0 , Predicted:  0\n",
      "Scan File:  IXI205-HH-1649-T1_bet_73.nii.gz , Actual:  1 , Predicted:  1\n",
      "Scan File:  IXI544-HH-2395-T1_bse_less_s51_r1.nii.gz , Actual:  0 , Predicted:  0\n",
      "Scan File:  IXI033-HH-1259-T1_bet_76.nii.gz , Actual:  1 , Predicted:  1\n",
      "Scan File:  IXI260-HH-1805-T1_bet_12.nii.gz , Actual:  0 , Predicted:  0\n",
      "Scan File:  IXI241-Guys-0833-T1_bse_high_s74_r2.nii.gz , Actual:  1 , Predicted:  1\n",
      "Scan File:  IXI569-Guys-1101-T1_bse_high_s75_r2.nii.gz , Actual:  1 , Predicted:  1\n",
      "Scan File:  IXI635-HH-2691-T1_bet_12.nii.gz , Actual:  0 , Predicted:  0\n",
      "Scan File:  IXI639-Guys-1088-T1_bet_85.nii.gz , Actual:  1 , Predicted:  1\n",
      "Scan File:  IXI035-IOP-0873-T1_bse_high_s8_r2.nii.gz , Actual:  1 , Predicted:  1\n",
      "Scan File:  IXI178-Guys-0778-T1_bet_5.nii.gz , Actual:  0 , Predicted:  0\n",
      "Scan File:  IXI390-Guys-0931-T1_bet_84.nii.gz , Actual:  1 , Predicted:  1\n",
      "Scan File:  IXI448-HH-2393-T1_bse_high_s74_r2.nii.gz , Actual:  1 , Predicted:  1\n",
      "Scan File:  IXI158-Guys-0783-T1_bet_06.nii.gz , Actual:  0 , Predicted:  0\n",
      "Scan File:  IXI118-Guys-0764-T1_bet_79.nii.gz , Actual:  1 , Predicted:  1\n",
      "Scan File:  IXI344-Guys-0905-T1_bet_01.nii.gz , Actual:  0 , Predicted:  0\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(10)):\n",
    "    prediction = model.predict(np.expand_dims(brain_scans_np[i], axis=0))[0]\n",
    "    print(\"Scan File: \", labels_to_file[i], \", Actual: \", labels_brain_feature[i], \", Predicted: \",round(float(prediction)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8a2b78cc-b27f-4a4c-ae07-586cace94537",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds_bf = []\n",
    "for i in range(len(labels_brain_feature_np)):\n",
    "    prediction = model.predict(np.expand_dims(brain_scans_np[i], axis=0))[0]\n",
    "    y_preds_bf.append(round(float(prediction)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "152f48ec-865c-4950-94b6-5cd1530c1d9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1311, 128, 128, 64)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brain_scans_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c85043ab-b2fc-4feb-a523-654688bcd0c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 128, 64)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brain_scans_np[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b67de014-d663-4c75-af11-ba287476845f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.71428573, 0.71428573, 0.71428573, 0.71428573, 0.71428573,\n",
       "       0.71428573, 0.71428573, 0.71428573, 0.71428573, 0.71428573,\n",
       "       0.71428573, 0.71428573, 0.71428573, 0.71428573, 0.71428573,\n",
       "       0.71428573, 0.71428573, 0.71428573, 0.71428573, 0.71428573,\n",
       "       0.71428573, 0.71428573, 0.71428573, 0.71428573, 0.71428573,\n",
       "       0.71428573, 0.71428573, 0.71428573, 0.71428573, 0.71428573,\n",
       "       0.71428573, 0.71428573, 0.71428573, 0.71428573, 0.71428573,\n",
       "       0.71428573, 0.71428573, 0.71428573, 0.71428573, 0.71428573,\n",
       "       0.71428573, 0.71428573, 0.71428573, 0.71428573, 0.71428573,\n",
       "       0.71428573, 0.71428573, 0.71428573, 0.71428573, 0.71428573,\n",
       "       0.71428573, 0.71428573, 0.71428573, 0.71428573, 0.71428573,\n",
       "       0.71428573, 0.71428573, 0.71428573, 0.71428573, 0.71428573,\n",
       "       0.71428573, 0.71428573, 0.71428573, 0.71428573], dtype=float32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brain_scans_np[0][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "af42e2df-341b-4e87-856e-913c8dbbb64d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3625613d-1929-4496-97d5-46d2c32d44c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Facial Features:\n",
      "------------------------------\n",
      "Confusion Matrix:\n",
      " [[614   5]\n",
      " [ 14 678]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98       619\n",
      "           1       0.99      0.98      0.99       692\n",
      "\n",
      "    accuracy                           0.99      1311\n",
      "   macro avg       0.99      0.99      0.99      1311\n",
      "weighted avg       0.99      0.99      0.99      1311\n",
      "\n",
      "Accuracy: 0.9855072463768116\n"
     ]
    }
   ],
   "source": [
    "print(\"Facial Features:\\n{}\".format('-'*30))\n",
    "results = confusion_matrix(labels_facial_feature_np, y_preds_ff)\n",
    "print(\"Confusion Matrix:\\n\",results)\n",
    "print(classification_report(labels_facial_feature_np, y_preds_ff))\n",
    "print(\"Accuracy: {}\".format(accuracy_score(labels_facial_feature_np, y_preds_ff)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7c5f84c1-6e0e-4ae5-abb4-f53e5166931c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Facial Features:\n",
      "------------------------------\n",
      "Confusion Matrix:\n",
      " [[687  20]\n",
      " [  2 602]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.98       707\n",
      "           1       0.97      1.00      0.98       604\n",
      "\n",
      "    accuracy                           0.98      1311\n",
      "   macro avg       0.98      0.98      0.98      1311\n",
      "weighted avg       0.98      0.98      0.98      1311\n",
      "\n",
      "Accuracy: 0.9832189168573608\n"
     ]
    }
   ],
   "source": [
    "print(\"Facial Features:\\n{}\".format('-'*30))\n",
    "results = confusion_matrix(labels_brain_feature_np, y_preds_bf)\n",
    "print(\"Confusion Matrix:\\n\",results)\n",
    "print(classification_report(labels_brain_feature_np, y_preds_bf))\n",
    "print(\"Accuracy: {}\".format(accuracy_score(labels_brain_feature_np, y_preds_bf)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd91d24-58d2-4d19-b563-c1d598756bfa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
