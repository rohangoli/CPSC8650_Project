{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import nibabel as nib\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from scipy import ndimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_nifti_file(filepath):\n",
    "    \"\"\"Read and load volume\"\"\"\n",
    "    # Read file\n",
    "    scan = nib.load(filepath)\n",
    "    # Get raw data\n",
    "    scan = scan.get_fdata()\n",
    "    return scan\n",
    "\n",
    "\n",
    "def normalize(volume):\n",
    "    \"\"\"Normalize the volume\"\"\"\n",
    "    min = -1000\n",
    "    max = 400\n",
    "    volume[volume < min] = min\n",
    "    volume[volume > max] = max\n",
    "    volume = (volume - min) / (max - min)\n",
    "    volume = volume.astype(\"float32\")\n",
    "    return volume\n",
    "\n",
    "\n",
    "def resize_volume(img):\n",
    "    \"\"\"Resize across z-axis\"\"\"\n",
    "    # Set the desired depth\n",
    "    desired_depth = 64\n",
    "    desired_width = 128\n",
    "    desired_height = 128\n",
    "    # Get current depth\n",
    "    current_depth = img.shape[-1]\n",
    "    current_width = img.shape[0]\n",
    "    current_height = img.shape[1]\n",
    "    # Compute depth factor\n",
    "    depth = current_depth / desired_depth\n",
    "    width = current_width / desired_width\n",
    "    height = current_height / desired_height\n",
    "    depth_factor = 1 / depth\n",
    "    width_factor = 1 / width\n",
    "    height_factor = 1 / height\n",
    "    # Rotate\n",
    "    img = ndimage.rotate(img, 90, reshape=False)\n",
    "    # Resize across z-axis\n",
    "    img = ndimage.zoom(img, (width_factor, height_factor, depth_factor), order=1)\n",
    "    return img\n",
    "\n",
    "\n",
    "def process_scan(path):\n",
    "    \"\"\"Read and resize volume\"\"\"\n",
    "    # Read scan\n",
    "    volume = read_nifti_file(path)\n",
    "    # Normalize\n",
    "    volume = normalize(volume)\n",
    "    # Resize width, height and depth\n",
    "    volume = resize_volume(volume)\n",
    "    return volume\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Brain scans: 4\n"
     ]
    }
   ],
   "source": [
    "scan_paths = [\n",
    "    os.path.join(os.getcwd(), \"../BET_BSE_DATA\", x)\n",
    "    for x in os.listdir(\"../BET_BSE_DATA\")\n",
    "]\n",
    "\n",
    "print(\"Brain scans: \" + str(len(scan_paths)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total no. of rows: 1312\n",
      "Field names are:Filename, Recognizable-Facial-Feature, Brain-Feature-Loss\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    " \n",
    "# csv file name\n",
    "filename = \"/home/joelkik/DataMining/BET_BSE_DATA/Label_file.csv\"\n",
    " \n",
    "# initializing the titles and rows list\n",
    "fields = []\n",
    "labels_dict = dict()\n",
    " \n",
    "# reading csv file\n",
    "with open(filename, 'r') as csvfile:\n",
    "    # creating a csv reader object\n",
    "    csvreader = csv.reader(csvfile)\n",
    "     \n",
    "    # extracting field names through first row\n",
    "    fields = next(csvreader)\n",
    " \n",
    "    # extracting each data row one by one\n",
    "    for row in csvreader:\n",
    "        #print(row)\n",
    "        if row[1].lower() == 'yes':\n",
    "            labels_dict[row[0]+'.gz'] = 1\n",
    "        else:\n",
    "            labels_dict[row[0]+'.gz'] = 0\n",
    " \n",
    "    # get total number of rows\n",
    "    print(\"Total no. of rows: %d\"%(csvreader.line_num))\n",
    " \n",
    "# printing the field names\n",
    "print('Field names are:' + ', '.join(field for field in fields))\n",
    "#print(labels_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "from scipy import ndimage\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def rotate(volume):\n",
    "    \"\"\"Rotate the volume by a few degrees\"\"\"\n",
    "\n",
    "    def scipy_rotate(volume):\n",
    "        # define some rotation angles\n",
    "        angles = [-20, -10, -5, 5, 10, 20]\n",
    "        # pick angles at random\n",
    "        angle = random.choice(angles)\n",
    "        # rotate volume\n",
    "        volume = ndimage.rotate(volume, angle, reshape=False)\n",
    "        volume[volume < 0] = 0\n",
    "        volume[volume > 1] = 1\n",
    "        return volume\n",
    "\n",
    "    augmented_volume = tf.numpy_function(scipy_rotate, [volume], tf.float32)\n",
    "    return augmented_volume\n",
    "\n",
    "\n",
    "def train_preprocessing(volume, label):\n",
    "    \"\"\"Process training data by rotating and adding a channel.\"\"\"\n",
    "    # Rotate volume\n",
    "    volume = rotate(volume)\n",
    "    volume = tf.expand_dims(volume, axis=3)\n",
    "    return volume, label\n",
    "\n",
    "\n",
    "def validation_preprocessing(volume, label):\n",
    "    \"\"\"Process validation data by only adding a channel.\"\"\"\n",
    "    volume = tf.expand_dims(volume, axis=3)\n",
    "    return volume, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read and process the scans.\n",
    "# Each scan is resized across height, width, and depth and rescaled.\n",
    "brain_scans=[]\n",
    "labels_facial_feature=[]\n",
    "labels_to_file=[]\n",
    "for path in os.listdir(\"/home/joelkik/DataMining/BET_BSE_DATA/files\"):\n",
    "    brain_scans.append(process_scan(\"/home/joelkik/DataMining/BET_BSE_DATA/files/\"+path))\n",
    "    labels_facial_feature.append(labels_dict[path])\n",
    "    labels_to_file.append(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "brain_scans_np = np.array(brain_scans)\n",
    "labels_facial_feature_np = np.array(labels_facial_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_val, y_train, y_val = train_test_split(brain_scans, labels_facial_feature, test_size=0.20, random_state=42)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_train, y_train, test_size=0.20, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data loaders.\n",
    "train_loader = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "validation_loader = tf.data.Dataset.from_tensor_slices((x_val, y_val))\n",
    "\n",
    "batch_size = 2\n",
    "# Augment the on the fly during training.\n",
    "train_dataset = (\n",
    "    train_loader.shuffle(len(x_train))\n",
    "    .map(train_preprocessing)\n",
    "    .batch(batch_size)\n",
    "    .prefetch(2)\n",
    ")\n",
    "# Only rescale.\n",
    "validation_dataset = (\n",
    "    validation_loader.shuffle(len(x_val))\n",
    "    .map(validation_preprocessing)\n",
    "    .batch(batch_size)\n",
    "    .prefetch(2)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels tf.Tensor([0 1], shape=(2,), dtype=int32) <TakeDataset shapes: (<unknown>, (None,)), types: (tf.float32, tf.int32)>\n",
      "Dimension of the CT scan is: (128, 128, 64, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x151cf578fdf0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data = train_dataset.take(1)\n",
    "images, labels = list(data)[0]\n",
    "images = images.numpy()\n",
    "image = images[0]\n",
    "print(\"labels\", labels, data)\n",
    "print(\"Dimension of the CT scan is:\", image.shape)\n",
    "plt.imshow(np.squeeze(image[:, :, 30]), cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"3dcnn\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 128, 128, 64, 1)  0         \n",
      "                             ]                                   \n",
      "                                                                 \n",
      " conv3d (Conv3D)             (None, 126, 126, 62, 64)  1792      \n",
      "                                                                 \n",
      " max_pooling3d (MaxPooling3D  (None, 63, 63, 31, 64)   0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 63, 63, 31, 64)   256       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " conv3d_1 (Conv3D)           (None, 61, 61, 29, 64)    110656    \n",
      "                                                                 \n",
      " max_pooling3d_1 (MaxPooling  (None, 30, 30, 14, 64)   0         \n",
      " 3D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 30, 30, 14, 64)   256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv3d_2 (Conv3D)           (None, 28, 28, 12, 128)   221312    \n",
      "                                                                 \n",
      " max_pooling3d_2 (MaxPooling  (None, 14, 14, 6, 128)   0         \n",
      " 3D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 14, 14, 6, 128)   512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv3d_3 (Conv3D)           (None, 12, 12, 4, 256)    884992    \n",
      "                                                                 \n",
      " max_pooling3d_3 (MaxPooling  (None, 6, 6, 2, 256)     0         \n",
      " 3D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 6, 6, 2, 256)     1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " global_average_pooling3d (G  (None, 256)              0         \n",
      " lobalAveragePooling3D)                                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               131584    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,352,897\n",
      "Trainable params: 1,351,873\n",
      "Non-trainable params: 1,024\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def get_model(width=128, height=128, depth=64):\n",
    "    \"\"\"Build a 3D convolutional neural network model.\"\"\"\n",
    "\n",
    "    inputs = keras.Input((width, height, depth, 1))\n",
    "\n",
    "    x = layers.Conv3D(filters=64, kernel_size=3, activation=\"relu\")(inputs)\n",
    "    x = layers.MaxPool3D(pool_size=2)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "\n",
    "    x = layers.Conv3D(filters=64, kernel_size=3, activation=\"relu\")(x)\n",
    "    x = layers.MaxPool3D(pool_size=2)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "\n",
    "    x = layers.Conv3D(filters=128, kernel_size=3, activation=\"relu\")(x)\n",
    "    x = layers.MaxPool3D(pool_size=2)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "\n",
    "    x = layers.Conv3D(filters=256, kernel_size=3, activation=\"relu\")(x)\n",
    "    x = layers.MaxPool3D(pool_size=2)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "\n",
    "    x = layers.GlobalAveragePooling3D()(x)\n",
    "    x = layers.Dense(units=512, activation=\"relu\")(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "\n",
    "    outputs = layers.Dense(units=1, activation=\"sigmoid\")(x)\n",
    "\n",
    "    # Define the model.\n",
    "    model = keras.Model(inputs, outputs, name=\"3dcnn\")\n",
    "    return model\n",
    "\n",
    "\n",
    "# Build model.\n",
    "model = get_model(width=128, height=128, depth=64)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(\"/home/joelkik/DataMining/CPSC8650_Project/3d_brain_image_classification.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "524/524 [==============================] - 6136s 12s/step - loss: 0.3667 - acc: 0.7948 - val_loss: 0.1727 - val_acc: 0.9620\n",
      "Epoch 2/100\n",
      "524/524 [==============================] - 6130s 12s/step - loss: 0.2695 - acc: 0.8979 - val_loss: 0.0688 - val_acc: 0.9848\n",
      "Epoch 3/100\n",
      "524/524 [==============================] - 6126s 12s/step - loss: 0.2207 - acc: 0.9351 - val_loss: 0.0879 - val_acc: 0.9848\n",
      "Epoch 4/100\n",
      "210/524 [===========>..................] - ETA: 1:01:01 - loss: 0.1675 - acc: 0.9429"
     ]
    }
   ],
   "source": [
    "# Compile model.\n",
    "initial_learning_rate = 0.0001\n",
    "lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate, decay_steps=100000, decay_rate=0.96, staircase=True\n",
    ")\n",
    "model.compile(\n",
    "    loss=\"binary_crossentropy\",\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=lr_schedule),\n",
    "    metrics=[\"acc\"],\n",
    ")\n",
    "\n",
    "# Define callbacks.\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\n",
    "    \"3d_brain_image_classification.h5\", save_best_only=True\n",
    ")\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(monitor=\"val_acc\", patience=15)\n",
    "\n",
    "# Train the model, doing validation at the end of each epoch\n",
    "epochs = 100\n",
    "model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=validation_dataset,\n",
    "    epochs=epochs,\n",
    "    shuffle=True,\n",
    "    verbose=1,\n",
    "    callbacks=[checkpoint_cb, early_stopping_cb],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(20, 3))\n",
    "ax = ax.ravel()\n",
    "\n",
    "for i, metric in enumerate([\"acc\", \"loss\"]):\n",
    "    ax[i].plot(model.history.history[metric])\n",
    "    ax[i].plot(model.history.history[\"val_\" + metric])\n",
    "    ax[i].set_title(\"Model {}\".format(metric))\n",
    "    ax[i].set_xlabel(\"epochs\")\n",
    "    ax[i].set_ylabel(metric)\n",
    "    ax[i].legend([\"train\", \"val\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(\"/home/joelkik/DataMining/CPSC8650_Project/3d_brain_image_classification.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scan File:  IXI476-IOP-1140-T1_bse_less_s47_r1.nii.gz , Actual:  1 , Predicted:  1\n",
      "Scan File:  IXI048-HH-1326-T1_bse_less_s44_r1.nii.gz , Actual:  1 , Predicted:  1\n",
      "Scan File:  IXI554-Guys-1068-T1_bet_18.nii.gz , Actual:  1 , Predicted:  1\n",
      "Scan File:  IXI115-Guys-0738-T1_bse_high_s76_r2.nii.gz , Actual:  0 , Predicted:  0\n",
      "Scan File:  IXI156-Guys-0837-T1_bse_less_s42_r1.nii.gz , Actual:  1 , Predicted:  1\n",
      "Scan File:  IXI218-HH-1815-T1_bse_high_s74_r2.nii.gz , Actual:  0 , Predicted:  0\n",
      "Scan File:  IXI038-Guys-0729-T1_bet_85.nii.gz , Actual:  0 , Predicted:  0\n",
      "Scan File:  IXI464-IOP-1029-T1_bse_default.nii.gz , Actual:  1 , Predicted:  1\n",
      "Scan File:  IXI435-IOP-1040-T1_bet_82.nii.gz , Actual:  0 , Predicted:  0\n",
      "Scan File:  IXI350-Guys-0908-T1_bet_82.nii.gz , Actual:  0 , Predicted:  0\n",
      "Scan File:  IXI013-HH-1212-T1_bet_19.nii.gz , Actual:  1 , Predicted:  1\n",
      "Scan File:  IXI607-Guys-1097-T1_bse_less_s56_r1.nii.gz , Actual:  1 , Predicted:  1\n",
      "Scan File:  IXI350-Guys-0908-T1_bet_1.nii.gz , Actual:  1 , Predicted:  1\n",
      "Scan File:  IXI385-HH-2078-T1_bet_05.nii.gz , Actual:  1 , Predicted:  1\n",
      "Scan File:  IXI627-Guys-1103-T1_bse_less_s56_r1.nii.gz , Actual:  1 , Predicted:  1\n",
      "Scan File:  IXI015-HH-1258-T1_bet_14.nii.gz , Actual:  1 , Predicted:  1\n",
      "Scan File:  IXI099-Guys-0748-T1_bet_88.nii.gz , Actual:  0 , Predicted:  0\n",
      "Scan File:  IXI606-HH-2601-T1_bet_05.nii.gz , Actual:  1 , Predicted:  1\n",
      "Scan File:  IXI178-Guys-0778-T1_bet_1.nii.gz , Actual:  1 , Predicted:  1\n",
      "Scan File:  IXI619-Guys-1099-T1_bse_high_s78_r2.nii.gz , Actual:  0 , Predicted:  0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in range(20):\n",
    "    prediction = model.predict(np.expand_dims(brain_scans_np[i], axis=0))[0]\n",
    "    print(\"Scan File: \", labels_to_file[i], \", Actual: \", labels_facial_feature_np[i], \", Predicted: \",round(float(prediction)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
